# # -*- coding: utf-8 -*-
# """Final_Siamese_Demo.ipynb

# Automatically generated by Colaboratory.

# Original file is located at
#     https://colab.research.google.com/drive/1oFvFPxs2UgpksXpRCD-DSrkRhGNis6c6
# """

# from google.colab import drive

# drive.mount('/content/gdrive')

# # Commented out IPython magic to ensure Python compatibility.
# # %cd /content/gdrive/My Drive/covid_detection



import os
from os import path, listdir
from os.path import join, isfile
from glob import glob
from pathlib import Path
import cv2

import random
import numpy as np
import pandas as pd
import random
from tqdm.notebook import tqdm
from sklearn.model_selection import train_test_split

import PIL.Image as Image
import matplotlib.pyplot as plt

from IPython.core.display import display, HTML
display(HTML("<style>.container { width:95% !important; }</style>"))

covid_images_path = os.path.join("images", "covid") 
normal_images_path = os.path.join("images", "normal")
severe_convid_images_path = os.path.join("images", "SevereCOVID_19")
pneumonia_images_path = os.path.join("images", "Pneumonia")

covid_images = [os.path.join(covid_images_path, f) for f in listdir(covid_images_path) if isfile(join(covid_images_path, f))]
normal_images = [os.path.join(normal_images_path, f) for f in listdir(normal_images_path) if isfile(join(normal_images_path, f))]
severe_covid_images = [os.path.join(severe_convid_images_path, f) for f in listdir(severe_convid_images_path) if isfile(join(severe_convid_images_path, f))]
pneumonia_images = [os.path.join(pneumonia_images_path, f) for f in listdir(pneumonia_images_path) if isfile(join(pneumonia_images_path, f))]

print(f"Total covid_images: {len(covid_images)}")
print(f"Total normal_images: {len(normal_images)}")
print(f"Total severe_covid_images: {len(severe_covid_images)}")
print(f"Total pneumonia_images: {len(pneumonia_images)}")

dataset = []    
for file in covid_images:    
    dataset.append([Path(covid_images[0]).parent.name, file])

for file in normal_images:    
    dataset.append([Path(normal_images[0]).parent.name, file])
    
for file in severe_covid_images:    
    dataset.append([Path(severe_covid_images[0]).parent.name, file])
    
for file in pneumonia_images:    
    dataset.append([Path(pneumonia_images[0]).parent.name, file])
    
pd.set_option('max_colwidth', 500)
df = pd.DataFrame(dataset)
df.columns = ['Class', 'Path']
total_labels = len(set(df['Class'].values))
labels = set(df['Class'].values)

print(f"Total number of labels: {total_labels}")
print(df.info())

# df.sample(n=5)

image_shape = (100, 100, 3)

def resize_image(img_array):
    img = Image.fromarray(img_array)
    img = img.resize(image_shape[:-1])
    return np.array(img)

def show_images(images, title=""):
    fig, ax = plt.subplots(1, len(images), figsize=(10, 10), dpi=100)   
    for i, img in enumerate(images):
        ax[i].imshow(img)
        ax[i].set_title(title)
    [x.axis('off') for x in ax]
    plt.show()
    
def load_images(image_paths):
    images = [np.array(Image.open(img).convert('RGB')) for img in image_paths]
    images = [resize_image(img) for img in images]    
    return np.array(images)

train_list = []
test_list = []

for l in labels:   
    char_imgs = df[df['Class']==l]
    
    print(l)
    df_train, df_test = train_test_split(char_imgs, test_size=0.6, random_state=42)
    train_list.append(df_train)
    
df_X_train = pd.concat(train_list)

import json
import os
from pathlib import Path

import numpy as np
import tensorflow as tf
from keras import backend as K
from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping
from keras.applications import ResNet50, VGG16, ResNet50V2
from keras.applications.mobilenet_v2 import MobileNetV2
from keras.applications.densenet import DenseNet121
from tensorflow.python.keras.backend import set_session
from keras.engine.saving import model_from_json
from keras.layers import Input, Dropout, Conv2D, MaxPooling2D
from keras.layers.core import Lambda, Flatten, Dense
from keras.models import Model, load_model
from keras.models import Sequential
from keras.optimizers import Adam
from keras.regularizers import l2
from keras.utils import plot_model

from sklearn.metrics import precision_recall_fscore_support

import warnings
warnings.filterwarnings('ignore')

test_image = []

model = load_model('weights/siamese_model_resnet_4classes_new_weights.hd5')

class Classify(object):
    
    def __init__(self, test_image, df_train, image_shape):
        # Prepare parameters
        self.df_test = df_test.copy()
        self.df_train = df_train.copy()
        self.h, self.w, self.c = image_shape
        self.labels_train = list(set(self.df_train['Class']))
    
    
    def resize_image(self, img_array):
        img = Image.fromarray(img_array)
        img = img.resize(image_shape[:-1])
        return np.array(img)

    def load_image(self, url):
        img = Image.open(url).convert('RGB')
        img = np.array(img)
        img = resize_image(img)
        img = np.divide(img, 255)
        return img

    def get_batch(self, image):
        
      anchorImage = image

      # Place holder for images
      pairs = [np.zeros((len(self.labels_train), self.h, self.w, self.c)) for i in range(2)]

      target_df = {}
      k=0
      for i in self.labels_train:
        image2 = self.df_train[self.df_train['Class'] == i].sample(n=1,random_state=1)['Path'].values[0]
        image2 = self.load_image(image2)
        pairs[0][k, :, :, :] = anchorImage
        pairs[1][k, :, :, :] = image2
        target_df[k] = i
        k=k+1

      actual = selected_label

      return pairs, target_df
        
    def score(self, model):
        
        batch, targets = self.get_batch(test_image)
        # Make prediction
        pred = model.predict(batch)
        pred = np.argmax(pred)
        res = targets[pred]
         
        return res

classify = Classify(test_image,df_X_train,image_shape)

res = classify.score(model)

#